{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Protein Structures\n",
    "\n",
    "Load a trained diffusion model and generate protein backbone structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from src.model import DiffusionTransformer\n",
    "from src.diffusion import DiffusionSchedule\n",
    "from src.sampler import DiffusionSampler\n",
    "from src.geom import ca_bond_lengths, radius_of_gyration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the run directory\n",
    "RUN_DIR = Path(\"../runs/20251231_121024\")\n",
    "\n",
    "# Generation parameters\n",
    "NUM_SAMPLES = 10\n",
    "SEQ_LENGTH = 64  # Length of generated proteins\n",
    "SCALE_FACTOR = 10.0  # Same as training\n",
    "\n",
    "# Device\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoint\n",
    "checkpoint_path = RUN_DIR / \"model.pt\"\n",
    "checkpoint = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=False)\n",
    "\n",
    "# Extract model args\n",
    "args = checkpoint[\"args\"]\n",
    "print(\"Model hyperparameters:\")\n",
    "for k, v in args.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model with same architecture\n",
    "model = DiffusionTransformer(\n",
    "    d_model=args.get(\"d_model\", 128),\n",
    "    num_layers=args.get(\"num_layers\", 4),\n",
    "    num_heads=args.get(\"num_heads\", 4),\n",
    ")\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model = model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model parameters: {num_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create diffusion schedule and sampler\n",
    "schedule = DiffusionSchedule(T=1000).to(DEVICE)\n",
    "sampler = DiffusionSampler(model, schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate samples\n",
    "print(f\"Generating {NUM_SAMPLES} structures of length {SEQ_LENGTH}...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    samples = sampler.sample(\n",
    "        shape=(NUM_SAMPLES, SEQ_LENGTH, 3),\n",
    "        device=DEVICE,\n",
    "        verbose=True,\n",
    "        use_self_cond=True,\n",
    "    )\n",
    "\n",
    "# Convert to numpy and unscale\n",
    "samples_np = samples.cpu().numpy() * SCALE_FACTOR\n",
    "print(f\"Generated samples shape: {samples_np.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Generated Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics for each sample\n",
    "print(\"\\nStructure metrics:\")\n",
    "print(f\"{'Sample':>6} {'Bond Mean':>10} {'Bond Std':>10} {'Valid %':>10} {'Rg':>10}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "all_bond_means = []\n",
    "all_bond_stds = []\n",
    "all_valid_pcts = []\n",
    "all_rgs = []\n",
    "\n",
    "for i, coords in enumerate(samples_np):\n",
    "    bonds = ca_bond_lengths(coords)\n",
    "    bond_mean = bonds.mean()\n",
    "    bond_std = bonds.std()\n",
    "    valid_pct = ((bonds > 3.6) & (bonds < 4.0)).mean() * 100\n",
    "    rg = radius_of_gyration(coords)\n",
    "    \n",
    "    all_bond_means.append(bond_mean)\n",
    "    all_bond_stds.append(bond_std)\n",
    "    all_valid_pcts.append(valid_pct)\n",
    "    all_rgs.append(rg)\n",
    "    \n",
    "    print(f\"{i:>6} {bond_mean:>10.2f} {bond_std:>10.2f} {valid_pct:>10.1f} {rg:>10.2f}\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Mean':>6} {np.mean(all_bond_means):>10.2f} {np.mean(all_bond_stds):>10.2f} {np.mean(all_valid_pcts):>10.1f} {np.mean(all_rgs):>10.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_structure_3d(coords, ax, title=\"\", color=\"blue\"):\n",
    "    \"\"\"Plot a protein backbone in 3D.\"\"\"\n",
    "    ax.plot(coords[:, 0], coords[:, 1], coords[:, 2], '-', color=color, linewidth=1.5, alpha=0.8)\n",
    "    ax.scatter(coords[0, 0], coords[0, 1], coords[0, 2], c='green', s=50, label='N-term')\n",
    "    ax.scatter(coords[-1, 0], coords[-1, 1], coords[-1, 2], c='red', s=50, label='C-term')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('X (Å)')\n",
    "    ax.set_ylabel('Y (Å)')\n",
    "    ax.set_zlabel('Z (Å)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all generated structures\n",
    "n_cols = 5\n",
    "n_rows = (NUM_SAMPLES + n_cols - 1) // n_cols\n",
    "\n",
    "fig = plt.figure(figsize=(4 * n_cols, 4 * n_rows))\n",
    "\n",
    "for i, coords in enumerate(samples_np):\n",
    "    ax = fig.add_subplot(n_rows, n_cols, i + 1, projection='3d')\n",
    "    plot_structure_3d(coords, ax, title=f\"Sample {i}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RUN_DIR / \"generated_structures.png\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Structures as PDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ca_pdb(coords: np.ndarray, path: Path, chain_id: str = \"A\"):\n",
    "    \"\"\"Save CA-only coordinates as a PDB file.\"\"\"\n",
    "    with open(path, \"w\") as f:\n",
    "        for i, (x, y, z) in enumerate(coords):\n",
    "            res_num = i + 1\n",
    "            # PDB ATOM format\n",
    "            f.write(\n",
    "                f\"ATOM  {i+1:5d}  CA  ALA {chain_id}{res_num:4d}    \"\n",
    "                f\"{x:8.3f}{y:8.3f}{z:8.3f}  1.00  0.00           C\\n\"\n",
    "            )\n",
    "        f.write(\"END\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all generated structures\n",
    "output_dir = RUN_DIR / \"generated_pdbs\"\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for i, coords in enumerate(samples_np):\n",
    "    pdb_path = output_dir / f\"sample_{i:02d}.pdb\"\n",
    "    save_ca_pdb(coords, pdb_path)\n",
    "    print(f\"Saved: {pdb_path}\")\n",
    "\n",
    "print(f\"\\nAll structures saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bond Length Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all bond lengths\n",
    "all_bonds = []\n",
    "for coords in samples_np:\n",
    "    bonds = ca_bond_lengths(coords)\n",
    "    all_bonds.extend(bonds)\n",
    "\n",
    "all_bonds = np.array(all_bonds)\n",
    "\n",
    "# Plot distribution\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.hist(all_bonds, bins=50, density=True, alpha=0.7, color='blue', label='Generated')\n",
    "ax.axvline(3.8, color='red', linestyle='--', linewidth=2, label='Ideal (3.8 Å)')\n",
    "ax.axvspan(3.6, 4.0, alpha=0.2, color='green', label='Valid range (3.6-4.0 Å)')\n",
    "ax.set_xlabel('CA-CA Bond Length (Å)')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title('Bond Length Distribution of Generated Structures')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(RUN_DIR / \"bond_distribution.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Bond length stats:\")\n",
    "print(f\"  Mean: {all_bonds.mean():.2f} Å\")\n",
    "print(f\"  Std:  {all_bonds.std():.2f} Å\")\n",
    "print(f\"  Valid %: {((all_bonds > 3.6) & (all_bonds < 4.0)).mean() * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Length Sweep\n\nTest how the model (trained on 128-residue windows) generalizes to different chain lengths.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Length sweep configuration\nSWEEP_LENGTHS = [32, 64, 96, 128, 192, 256]\nSAMPLES_PER_LENGTH = 10\n\n# Get training max_len for reference\ntrain_max_len = args.get(\"max_len\", 128)\nprint(f\"Model was trained with max_len={train_max_len}\")\nprint(f\"Sweeping lengths: {SWEEP_LENGTHS}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Generate samples at each length and collect metrics\nsweep_results = []\n\nfor length in SWEEP_LENGTHS:\n    print(f\"\\nGenerating {SAMPLES_PER_LENGTH} samples at length {length}...\")\n    \n    with torch.no_grad():\n        samples = sampler.sample(\n            shape=(SAMPLES_PER_LENGTH, length, 3),\n            device=DEVICE,\n            verbose=True,\n            use_self_cond=True,\n        )\n    \n    samples_np = samples.cpu().numpy() * SCALE_FACTOR\n    \n    # Compute metrics for each sample\n    for i, coords in enumerate(samples_np):\n        bonds = ca_bond_lengths(coords)\n        sweep_results.append({\n            \"length\": length,\n            \"sample\": i,\n            \"bond_mean\": bonds.mean(),\n            \"bond_std\": bonds.std(),\n            \"valid_pct\": ((bonds > 3.6) & (bonds < 4.0)).mean() * 100,\n            \"rg\": radius_of_gyration(coords),\n        })\n\nprint(f\"\\nGenerated {len(sweep_results)} total samples across {len(SWEEP_LENGTHS)} lengths\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Aggregate metrics by length\nprint(\"\\nLength Sweep Summary:\")\nprint(f\"{'Length':>8} {'Bond Mean':>12} {'Bond Std':>12} {'Valid %':>12} {'Rg':>12}\")\nprint(\"-\" * 60)\n\nlength_stats = {}\nfor length in SWEEP_LENGTHS:\n    length_results = [r for r in sweep_results if r[\"length\"] == length]\n    stats = {\n        \"bond_mean\": np.mean([r[\"bond_mean\"] for r in length_results]),\n        \"bond_std\": np.mean([r[\"bond_std\"] for r in length_results]),\n        \"valid_pct\": np.mean([r[\"valid_pct\"] for r in length_results]),\n        \"rg\": np.mean([r[\"rg\"] for r in length_results]),\n        # Also store std across samples for error bars\n        \"bond_mean_err\": np.std([r[\"bond_mean\"] for r in length_results]),\n        \"valid_pct_err\": np.std([r[\"valid_pct\"] for r in length_results]),\n        \"rg_err\": np.std([r[\"rg\"] for r in length_results]),\n    }\n    length_stats[length] = stats\n    \n    marker = \" <-- trained\" if length == train_max_len else \"\"\n    print(f\"{length:>8} {stats['bond_mean']:>12.2f} {stats['bond_std']:>12.2f} {stats['valid_pct']:>12.1f} {stats['rg']:>12.2f}{marker}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Visualize sweep results\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\n\nlengths = list(length_stats.keys())\nbond_means = [length_stats[l][\"bond_mean\"] for l in lengths]\nbond_errs = [length_stats[l][\"bond_mean_err\"] for l in lengths]\nvalid_pcts = [length_stats[l][\"valid_pct\"] for l in lengths]\nvalid_errs = [length_stats[l][\"valid_pct_err\"] for l in lengths]\nrgs = [length_stats[l][\"rg\"] for l in lengths]\nrg_errs = [length_stats[l][\"rg_err\"] for l in lengths]\n\n# Bond length vs chain length\nax = axes[0]\nax.errorbar(lengths, bond_means, yerr=bond_errs, marker='o', capsize=5, linewidth=2, markersize=8)\nax.axhline(3.8, color='red', linestyle='--', label='Ideal (3.8 Å)')\nax.axhspan(3.6, 4.0, alpha=0.2, color='green', label='Valid range')\nax.axvline(train_max_len, color='gray', linestyle=':', alpha=0.7, label=f'Trained ({train_max_len})')\nax.set_xlabel('Chain Length (residues)')\nax.set_ylabel('Mean Bond Length (Å)')\nax.set_title('Bond Length vs Chain Length')\nax.legend()\nax.grid(True, alpha=0.3)\n\n# Valid bond % vs chain length\nax = axes[1]\nax.errorbar(lengths, valid_pcts, yerr=valid_errs, marker='s', capsize=5, linewidth=2, markersize=8, color='green')\nax.axvline(train_max_len, color='gray', linestyle=':', alpha=0.7, label=f'Trained ({train_max_len})')\nax.set_xlabel('Chain Length (residues)')\nax.set_ylabel('Valid Bonds (%)')\nax.set_title('Bond Quality vs Chain Length')\nax.set_ylim(0, 105)\nax.legend()\nax.grid(True, alpha=0.3)\n\n# Radius of gyration vs chain length\nax = axes[2]\nax.errorbar(lengths, rgs, yerr=rg_errs, marker='^', capsize=5, linewidth=2, markersize=8, color='purple')\nax.axvline(train_max_len, color='gray', linestyle=':', alpha=0.7, label=f'Trained ({train_max_len})')\nax.set_xlabel('Chain Length (residues)')\nax.set_ylabel('Radius of Gyration (Å)')\nax.set_title('Compactness vs Chain Length')\nax.legend()\nax.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig(RUN_DIR / \"length_sweep.png\", dpi=150)\nplt.show()\n\nprint(f\"\\nSweep results saved to: {RUN_DIR / 'length_sweep.png'}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Interpreting the Sweep\n\n**What to look for:**\n\n1. **Bond Length**: Should stay close to 3.8 Å across all lengths. If it drifts at longer/shorter lengths, the model struggles to generalize.\n\n2. **Valid Bond %**: Higher is better (target: >90%). A sharp drop at certain lengths indicates the model breaks down.\n\n3. **Radius of Gyration**: Should increase with chain length (longer chains = larger structures). If Rg stays flat or decreases at longer lengths, the model may be \"collapsing\" structures.\n\n**Typical failure modes:**\n\n- **Short chains (< trained)**: Usually works well - model just uses part of its capacity\n- **Long chains (> trained)**: Often breaks down - positional encodings extrapolate poorly, structures may collapse or have poor geometry",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}